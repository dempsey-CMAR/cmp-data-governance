---
title: "Thresholds"
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, dpi = 600, fig.width = 8)

library(here)
library(lubridate)
library(plotly)
library(stringr)
library(summaryplots)

source(here("pages/import_data_and_params.R"))
source(here("functions/filter_out_suspect_obs.R"))

st_locations <- st_locations %>%
  left_join(do_units, by = "STATION")

# filter salinity data
dat_sal <- readRDS(here("pages/data/sal_rolling_sd_prelim_qc.rds")) %>%
  select(-c(sensor_type, int_sample, n_sample, rolling_sd_flag_salinity_psu)) %>%
  ss_pivot_longer() %>%
  select(
    COUNTY = county,
    STATION = station,
    DEPLOYMENT_PERIOD = deployment_range,
    TIMESTAMP = timestamp_utc,
    everything()) %>%
  mutate(VARIABLE = "Salinity", UNITS = "PSU") %>%
  filter_out_suspect_obs() %>%
  select(-c(VARIABLE, UNITS)) %>%
  rename(
    county = COUNTY,
    station = STATION,
    deployment_range = DEPLOYMENT_PERIOD,
    timestamp_utc = TIMESTAMP
  ) %>%
  ss_pivot_wider() %>%
  mutate(
    county_sal = if_else(county == "Inverness", "Inverness", "Other"),
    month = month(timestamp_utc)
  )

colnames(dat_sal) <- str_remove_all(colnames(dat_sal), "value_")
```

**Separate thresholds were calculated for salinity measured in units of percent saturation and salinity measured in units of mg per L. This page describes the thresholds for mg per L. Click [here](../pages/do_thresholds.qmd) for the thresholds for percent saturation.**

**QC test thresholds for salinity were based on historical Coastal Monitoring Program data. Preliminary quality control (QC) was applied to the historical data. Obvious outliers, suspected biofouling, and freshwater stations were omitted.**

**To date, salinity has only been measured in two counties[^1] in adjacent waterbodies[^2]. A single set of thresholds was determined for these counties.**



# Gross Range Test

## Sensor Thresholds

The sensor thresholds were determined based on the manual for the aquaMeasure SAL (Table 1).

::: panel-tabset

### Table 1

Table 1: Salinity sensor thresholds for the Gross Range Test.
```{r}
sensors %>%
  filter(str_detect(variable, "salinity")) %>%
  mutate(
    `Sensor (link to spec sheet)` =
      paste0('<a  target=_blank href=', url, '>', sensor_type,'</a>')
  ) %>%
  select(`Sensor (link to spec sheet)`, sensor_min, sensor_max) %>%
  datatable(options = dt_options2, rownames = FALSE, escape = FALSE)
```
:::

## User Thresholds

The salinity observations are relatively normally distributed (@fig-do-hist), and so the mean and standard deviation was used to determine $user_{min}$ and $user_{max}$. The statistics and threshold values are shown in Table 2.

:::panel-tabset

### Figure 1
```{r}
#| warning: false
#| fig-height: 4
#| fig-cap: Distribution of salinity observations (binwidth = 0.5 PSU). Dotted orange lines indicate the user thresholds.
#| label: fig-do-hist

user_sal <- dat_sal %>% 
  group_by(county_sal) %>% 
  qc_calculate_user_thresholds(
    var = "salinity_psu",
    n_sd = 3, keep_stats = TRUE
  ) %>% 
  pivot_wider(names_from = threshold, values_from = threshold_value) %>% 
  select(county_sal, mean = mean_var, stdev = sd_var, user_min, user_max) 

p <- plot_histogram(
  dat_sal, hist_col = salinity_psu, 
  binwidth = 0.5,
  pal= hist_pal
) +
  scale_x_continuous("Salinity (PSU)") +
  facet_wrap(~county_sal, ncol = 1) +
  geom_vline(
    data = user_sal, aes(xintercept = user_max), linetype = 3, col = "#EDA247"
  ) +
  geom_vline(
    data = user_sal, aes(xintercept = user_min), linetype = 3, col = "#EDA247"
  ) +
  theme(strip.background = element_rect(color = 1)) +
  theme_facet_plotly

ggplotly(p, tooltip = "text")
```

### Table 2

Table 2: Gross Range Test statistics and user thresholds for salinity.
```{r}
user_sal %>% 
  rename(county = county_sal) %>% 
  datatable(options = dt_options2, rownames = FALSE)
```
:::

# Climatological Test

**Didn't calculate these**

**@fig-do-clim shows the monthly mean and standard deviation of salinity data. The observations are normally distributed within each month (@fig-do-hist-clim), and so the mean and standard deviation were used to calculate the seasonal thresholds (Table 3).**

::: panel-tabset

### Figure 2
```{r}
#| fig-height: 5
#| fig-cap: Mean +/- 3 standard deviations of the monthly salinity observations.
#| label: fig-do-clim
#| message: false

do_clim <- dat_sal %>% 
  group_by(county_sal, month) %>% 
  summarise(
    mean = mean(salinity_psu), 
    stdev = sd(salinity_psu)
  ) %>% 
  mutate(
    variable = "salinity_psu",
    season_min = round(mean - 3 * stdev, digits = 3),
    season_max = round(mean + 3 * stdev, digits = 3)
  )

# # quick check
# do_thresh <- thresholds %>%
#   filter(variable == "salinity_psu", qc_test == "climatology") %>%
#   pivot_wider(names_from = threshold, values_from = threshold_value)
# 
# all.equal(do_clim$season_min, do_thresh$season_min)
# all.equal(do_clim$season_max, do_thresh$season_max)

p <- plot_mean_sd_season(do_clim, n_sd = 3, facet_county = FALSE) +
  scale_y_continuous("salinity (PSU)") +
  facet_wrap(~county_sal, ncol = 1) +
  theme(strip.background = element_rect(color = 1)) #+
  theme_facet_plotly
  
ggplotly(p)

```

### Figure 3
```{r}
#| warning: false
#| fig-height: 10
#| fig-cap:  Seasonal distribution of salinity observations (binwidth = 0.5 PSU). Dotted orange lines indicate the user thresholds. 
#| label: fig-do-hist-clim
#| message: false

# p <- dat_sal %>% 
#   plot_histogram(
#     hist_col = salinity_psu, binwidth = 0.5,
#     pal= hist_pal
#   ) +
#   geom_vline(
#     data = do_clim, aes(xintercept = season_min), linetype = 3, col = "#EDA247"
#   ) +
#   geom_vline(
#     data = do_clim, aes(xintercept = season_max), linetype = 3, col = "#EDA247"
#   ) +
#   scale_x_continuous("salinity (PSU)") +
#   facet_wrap(~month,  ncol = 3) +
#   theme(strip.background = element_rect(color = 1)) +
#   theme_facet_plotly
# 
# ggplotly(p, tooltip = "text")
```

### Table 3

Table 2: Climatology statistics and thresholds for salinity.
```{r}
# do_clim %>% 
#   mutate( 
#     season_mean = round(mean, digits = 3), 
#     season_stdev = round(stdev, digits = 3)
#   ) %>% 
#   select(month, season_mean, season_stdev, season_min, season_max) %>% 
#   datatable(options = dt_options, rownames = FALSE)
```

:::


# Spike Test

**probably could have used the same spike val**

The distribution of the spike value is skewed right (@fig-do-spike-dist), and so several upper quartile values (90th, 95th, and 99.7th quartile) were evaluated to use as the $spike_{low}$. 

There were relatively few large single-value spikes in the salinity data, and so the 99.7th quartile was selected to avoid false positives. $spike_{high}$ was defined as 3 * $spike_{low}$ to identify especially egregious spike values.

::: panel-tabset

### Figure 4
```{r}
#| warning: false
#| fig-height: 4
#| fig-cap: Distribution of the spike value of salinity (percent saturation) observations (binwidth = 0.1 %). Dotted orange line indicates spike_low; dotted red line indicates spike_high.
#| label: fig-do-spike-dist

spike_thresh <- thresholds %>% 
  filter(variable == "salinity_psu", qc_test == "spike") %>% 
  pivot_wider(names_from = threshold, values_from = threshold_value)

dat_sp <- dat_sal %>% 
  group_by(county, station, deployment_range, sensor_serial_number) %>%
  dplyr::arrange(timestamp_utc, .by_group = TRUE) %>%
  mutate(
    lag_value = lag(salinity_psu),
    lead_value = lead(salinity_psu),
    spike_ref = (lag_value + lead_value) / 2,
    spike_value = abs(salinity_psu - spike_ref)  
  ) %>% 
  filter(!is.na(spike_value))

p <- dat_sp %>% 
  plot_histogram(
    hist_col = spike_value, binwidth = 0.1, pal = hist_pal,
    user_thresh = spike_thresh$spike_low
  ) +
  facet_wrap(~county_sal, ncol = 1) +
  geom_vline(
    dat = spike_thresh, aes(xintercept = spike_high), 
    col = "#DB4325", linetype = 3
  ) +
  scale_x_continuous("Salinity (PSU)\nSpike Value") +
  theme(strip.background = element_rect(color = 1)) +
  theme_facet_plotly

ggplotly(p, tooltip = "text")

```

### Table 4

Table 4: Spike thresholds for salinity.
```{r}
spike_thresh %>% 
  select(spike_low, spike_high) %>% 
  datatable(options = dt_options2, rownames = FALSE)
```

:::

# Rolling Standard Deviation Test

The distribution of rolling standard deviation is skewed right (@fig-do-roll-sd-dist), and so several upper quartile values were evaluated to use as the $rolling\_sd\_max$. 

The 90th, 95th, and 99.7th quartile values were each applied to the the raw data (no preliminary QC) and the results inspected. The 90th quartile was determined to be too stringent, as it generated false positives, while The 99.7th quartile was determined to be too lenient, as it resulted in false negatives. The 95th quartile identified 23 % of the raw data (no preliminary QC) as [Suspect/Of Interest]{style="color: #EDA247;"} and was considered the most useful threshold.

As discussed for salinity (percent saturation), this is a very high percent of observations to flag as [Suspect/Of Interest]{style="color: #EDA247;"}. However, it was anticipated that a large proportion of the salinity observations would be flagged by this test because there were substantial biofouling signals identified during the preliminary QC process. CMAR is currently assessing options to reduce biofouling on salinity sensors.

There is no [Fail]{style="color: #DB4325;"} flag for the Rolling Standard Deviation Test because of the natural variability of the Water Quality variables. However, CMAR recommends that the salinity observations flagged as [Suspect/Of Interest]{style="color: #EDA247;"} should be considered [Suspect]{style="color: #EDA247;"}, and filtered out of most analyses. 

::: panel-tabset

### Figure 5
```{r}
#| warning: false
#| fig-height: 4
#| fig-cap: Distribution of the 24-hour rolling standard deviation of salinity observations (binwidth = 0.1 PSU). Shaded green area shows observations that wil be flagged “Pass”, and shaded orange area shows observations that will be flagged as “Suspect / Of Interest" by the Rolling Standard Deviation Test.
#| label: fig-do-roll-sd-dist

do_roll_sd <- thresholds %>% 
  filter(
    variable == "salinity_psu",
         qc_test == "rolling_sd"
    ) %>% 
  select(threshold, threshold_value) %>% 
  pivot_wider(names_from = threshold, values_from = threshold_value) 

p <- dat_sal %>% 
  filter(!is.na(sd_roll)) %>% 
    plot_histogram(
    hist_col = sd_roll, binwidth = 0.1, pal = hist_pal,
    user_thresh = do_roll_sd$rolling_sd_max
  ) +
  scale_x_continuous("Salinity (PSU)\nRolling Standard Deviation")

ggplotly(p, tooltip = "text")

```

### Table 5

Table 5: Rolling standard deviation threshold for salinity.
```{r}
do_roll_sd %>% 
  datatable(options = dt_options2, rownames = FALSE)
```
:::
